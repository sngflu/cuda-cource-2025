# Lab 2: Matrix Multiplication

## Описание

Реализована программа для умножения прямоугольных матриц вида `MxK @ KxN` на графическом процессоре с использованием CUDA

Программа:
- Поддерживает произвольные размеры матриц через аргументы командной строки
- Сравнивает результат с CPU-реализацией (проверка корректности)
- Измеряет и выводит время выполнения на CPU и GPU, а также ускорение

## Компиляция

```bash
make
```

## Запуск 

```bash
./matmul [M] [K] [N]
```

### Маленькие прямоугольные матрицы

```bash
./matmul 64 128 256
Матрицы: A[64x128] * B[128x256] = C[64x256]
Время на CPU: 0.007 сек
Время на GPU: 0.00011472 сек
Ускорение: 61.0181x
Результат корректен!
```

### Квадратные матрицы побольше

```bash
./matmul 512 512 512
Матрицы: A[512x512] * B[512x512] = C[512x512]
Время на CPU: 0.753 сек
Время на GPU: 0.0011919 сек
Ускорение: 631.762x
Результат корректен!
```

## Результаты

* Программа корректно работает для положительных целых M, K, N
* На Google Colab (GPU Tesla T4, архитектура sm_75) достигается ускорение от 50x до 650x в зависимости от размеров. Чем больше матрицы, тем значительнее прирост производительности относительно CPU
* Проверка корректности подтверждает совпадение результатов CPU и GPU с точностью до 1e-3


| A         | B         | CPU, сек | GPU, сек | Ускорение |
|-----------|-----------|----------|----------|-----------|
| 64x128    | 128x256   | 0.007    | 0.0001   | 61.02x    |
| 512x512   | 512x512   | 0.753    | 0.0012   | 631.76x   |
| 1024x512  | 512x2045  | 5.75     | 0.0093   | 615.99x   |
| 2048x2048 | 2048x2048 | 115.866  | 0.0752   | 1541.31x  |

## Замечания

* Реализация использует наивный алгоритм без shared memory и тайлинга. Это ограничивает производительность для очень больших `K`, но упрощает код и демонстрирует базовые принципы CUDA
